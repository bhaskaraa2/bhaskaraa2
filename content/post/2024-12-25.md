---
author: bhaskar
title: Introduction Apache Iceberg
date: 2024-12-24
description:
tags:
categories:
  - Apache Iceberg
---

Apache Iceberg is a modern table format for large analytic datasets. Here are
its key features and characteristics:

Core Features:

- Schema evolution with full backward compatibility
- Hidden partitioning (users don't need to specify partition columns in queries)
- Time travel and snapshot isolation
- ACID transaction guarantees
- Support for optimistic concurrency control
- Format-preserving encryption support

Key Benefits:

- Efficient handling of large-scale data
- Better performance through metadata management
- Reliable version control for data
- Seamless integration with popular tools like:
  - Apache Spark
  - Apache Flink
  - Apache Hive
  - Presto/Trino
  - Dremio

Technical Aspects:

- Uses a table format based on JSON metadata files
- Maintains manifest files for tracking data files
- Supports multiple file formats:
  - Parquet
  - ORC
  - Avro

Use Cases:

- Data lakes
- Large-scale analytics
- Streaming data processing
- Multi-table, multi-user data warehouses

Iceberg addresses many limitations of traditional Hive-style partitioning and
provides a more robust foundation for modern data lake architectures.

## Quick start

https://github.com/databricks/docker-spark-iceberg

## Case Study: Branch.io

Source: https://www.youtube.com/watch?v=WrDBI4Baw6o

### Initial Data Platform Architecture

```goat
+-------------+     +---------+     +----------+     +---------+
| Microservice|---->| Kafka   |---->| Avro S3  |---->| Parquet |
+-------------+     +---------+     +----------+     +---------+
                                                         |
                                    +------------+   +----------+
                                    | Trino/     |<--| Hive    |
                                    | Presto     |   | Metastore|
                                    +------------+   +----------+
```

**Scale Metrics:**

- 40 billion daily events
- 100TB daily data ingestion
- 500+ Hive tables
- 10PB total data size

**Key Components:**

- Kafka for message passing
- Apache Flink for streaming
- Apache Spark for batch processing
- S3 storage with Parquet format
- Hive Metastore for metadata
- Trino for ad-hoc queries

### Challenges with Parquet

1. **Mutability Issues:**

   - Unsafe data changes requiring full partition rewrites
   - Long processing times for data deletion requests
   - Two-step transaction process leading to potential data visibility issues

2. **Query Performance:**
   - Limited optimization options (only partition filtering)
   - Large data scans for specific customer queries
   - Complex workarounds needed for performance improvement

### Iceberg Migration Architecture

```goat
+-------------+     +---------+     +---------------+
| Microservice|---->| Kafka   |---->| Iceberg Tables|
+-------------+     +---------+     +---------------+
                                          |
                    +------------+   +----------+
                    | Analytics  |<--| Iceberg  |
                    | Warehouse  |   | Metadata |
                    +------------+   +----------+
```

**Migration Strategy:**

- Parallel table creation approach
- Double-write strategy during migration
- Quality check processes
- Backfill process for historical data

**Tools Developed:**

1. Column Metrics Configuration
2. Disaster Recovery Tool
3. Table Maintainer Process
4. Monitoring and Alerting System

### Benefits Achieved

1. **Performance:**

   - 20x improvement for customer ID filtered queries
   - 20-50% reduction in other query times
   - 40% cost reduction for specific data products

2. **Storage:**

   - 18% reduction in storage costs
   - Better utilization of S3 Intelligent-Tiering

3. **Development:**
   - Simplified schema management
   - Easier merge operations
   - Improved data quality processes

This migration showcases a successful implementation of Apache Iceberg in a
large-scale data platform, delivering significant improvements in performance,
cost, and operational efficiency.

## Related Ideas

## Shared storage

- Allows multiple engines to access the same data directly
- Eliminates need for data duplication across systems
- Enables centralization of data storage
- Simplifies data integration during company mergers/acquisitions

Magnus Architecture (ByteDance's Enhanced Iceberg):

Computing Layer:

- ETL: Spark, Flink, Krypton
- Training: Primus, PyTorch, TensorFlow, Ray
- Cross-language support via Arrow

Core Layer:

- Column-level updates
- Git-like branching
- High-speed vectorized merge-read engine
- Global indexing with HBase

Storage Layer:

- Multiple file formats support
- 30-50% storage savings
- HDFS/object storage backend

## References

- Shared warehouse storage, the quiet revolution led by Apache Iceberg - YouTube
  https://www.youtube.com/watch?v=_kYKTQq14Tc
- Building an EB Scale Feature Store at ByteDance - YouTube
  https://www.youtube.com/watch?v=UPjr0qZ0-Do
- From Hive to Iceberg Crowdstrikeâ€™s Journey - YouTube
  https://www.youtube.com/watch?v=cFBSr-4pdBs
- Journey to the Iceberg Parquet to Iceberg Migration (Branch.io) - YouTube
  https://www.youtube.com/watch?v=WrDBI4Baw6o
- Unleashing Analytical Productivity at Pinterest with Apache Iceberg - YouTube
  https://www.youtube.com/watch?v=k8MUTt0qh6s
- Leveraging Iceberg in Netflix Studio and Creative Production - YouTube
  https://www.youtube.com/watch?v=xrMaG2G7KX0
